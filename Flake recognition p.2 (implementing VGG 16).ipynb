{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking images containing monolayers and grouping them into a separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "x = np.loadtxt('C:/Users/Evgeniy/Desktop/Advanced computing/flakes/monolayer_labels.txt', delimiter=',')\n",
    "lb=np.int16(x)\n",
    "k=0\n",
    "\n",
    "\n",
    "for j in range (0,3025,1):\n",
    "    if k< len(lb) and j==lb[k]:\n",
    "        im = Image.open('C:/Users/Evgeniy/Desktop/Advanced computing/flakes/treated/tr'+str(j)+'.jpg')    \n",
    "        im.save('C:/Users/Evgeniy/Desktop/Advanced computing/flakes/monolayers/tr'+str(j)+'.jpg')\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use a balanced data set containing equal amount of images with and without monolayers I pick random images not labeled as monolayer-containing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "k=0\n",
    "mlist=[]\n",
    "m=0\n",
    "while k < len(lb):\n",
    "    m=random.randint(1,3024)\n",
    "    if m not in lb and m not in mlist: \n",
    "        k=k+1\n",
    "        im = Image.open('C:/Users/Evgeniy/Desktop/Advanced computing/flakes/treated/tr'+str(m)+'.jpg')    \n",
    "        im.save('C:/Users/Evgeniy/Desktop/Advanced computing/flakes/not_monolaeyrs/tr'+str(m)+'.jpg')\n",
    "        mlist.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evgeniy\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# for example load the VGG16 network\n",
    "model = applications.VGG16(include_top=False,\n",
    "                           weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating features using pre-trained VGG 16 CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def compute_features(directory):\n",
    "    features = []\n",
    "    fl_imgs = os.listdir(directory)\n",
    "    for flake in fl_imgs:\n",
    "        img_path = directory + flake\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        features_ = model.predict(x)\n",
    "        features.append(features_.ravel())\n",
    "        \n",
    "    return features\n",
    "\n",
    "ml_features = compute_features('C:/Users/Evgeniy/Desktop/Advanced computing/flakes/monolayers/')\n",
    "non_ml_features = compute_features('C:/Users/Evgeniy/Desktop/Advanced computing/flakes/not_monolaeyrs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ml_features + non_ml_features\n",
    "X = np.array(X)\n",
    "y = [1] * len(ml_features) + [0] * len(non_ml_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evgeniy\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Evgeniy\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1e-10, 1e-08, 1e-06, 0.0001, 0.01, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "lr = LogisticRegression()\n",
    "\n",
    "grid = GridSearchCV(lr, {'C': [1e-010, 1e-08, 1e-06, 1e-04, 1e-02, 0.1]}, cv=7)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.0001}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8979591836734694"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing random forest classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=7, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [20, 50, 100, 200, 500]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "RFC=RandomForestClassifier()\n",
    "grid = GridSearchCV(RFC, {'n_estimators': [20,50,100,200,500] }, cv=7)\n",
    "grid.fit(X_train, y_train)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination of pre-trained VGG 16 as feature extractor and linear regression yields values of accuracy of about 0.9 which looks quite reasonable. That shows the possibility of implementing CNN trained on some 'conventional' images for some specific research applications as flake thickness recognition presented here. \n",
    "\n",
    "The implementation discussed here is the most simple ground-level problem (whether a monolayer is present or not). The more useful application can be determination of exact thickness of presented flakes (2,3...10 layers) which can be viewed as a next step.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
